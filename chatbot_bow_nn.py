# -*- coding: utf-8 -*-
"""chatbot_BOW_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15UDZU00Ne__1GU1QFKRmQtb2Hv_wVUQF
"""

import json
import string
import random
import nltk
import numpy as np
import logging
from nltk.stem import WordNetLemmatizer
from keras_architecture_visualizer import KerasArchitectureVisualizer

import tensorflow as tensorF
import warnings
import os

from colorama import Fore
from pickling import startPickling
from tensorflow.keras import Sequential 
from tensorflow.keras.layers import Dense, Dropout

# print(tensorF.__version__)


# logging.disable(logging.CRITICAL)
# warnings.filterwarnings("ignore")
# logging.disable(logging.WARNING)
# logging.disable(logging.ERROR)
# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 
# tensorF.get_logger().setLevel(logging.ERROR)
# logger = logging.getLogger('my-logger')
# logger.propagate = False
# logging.getLogger().disabled = True


nltk.download("punkt")
nltk.download("wordnet")
nltk.download('omw-1.4')

# f=open('intents.json')
f=open('intents-v2.json')
data =json.load(f)


lm = WordNetLemmatizer()
ourClasses=[]
newWords=[]
docPattern=[]
docTag=[]

for intent in data['intents']:
    for pattern in intent['patterns']:
        ourNewTokens = nltk.word_tokenize(pattern)
        newWords.extend(ourNewTokens)
        docPattern.append(pattern)
        docTag.append(intent['tag'])
    if intent['tag'] not in ourClasses:
        ourClasses.append(intent['tag'])       


newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation]
newWords = sorted(set(newWords))

ourClasses=sorted(set(ourClasses))

trainingData = []
outEmpty=[0]*len(ourClasses)

for i,doc in enumerate(docPattern):
  bagOfWords=[]
  text=lm.lemmatize(doc.lower())

  for word in newWords:
    bagOfWords.append(1) if word in text else bagOfWords.append(0)
  outputRow = list(outEmpty)
  outputRow[ourClasses.index(docTag[i])]=1
  trainingData.append([bagOfWords,outputRow])

random.shuffle(trainingData)
trainingData = np.array(trainingData,dtype=object)

x = np.array(list(trainingData[:, 0]))
y = np.array(list(trainingData[:, 1]))

iShape = (len(x[0]),)
oShape = len(y[0])

print(iShape,oShape)

model =Sequential()
model.add(Dense(128,input_shape=iShape,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64,activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(oShape,activation='softmax'))
md = tensorF.keras.optimizers.Adam(learning_rate=0.01,decay=1e-6)
model.compile(loss='categorical_crossentropy',
                    optimizer=md,
                    metrics=['accuracy'])
model.fit(x,y,epochs=200,verbose=0)

os.environ["PATH"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'
from ann_visualizer.visualize import ann_viz;
ann_viz(model, title="Neural network")


#######################tflite#############################

# model = tensorF.keras.models.load_model('model.h5')
# converter = tensorF.lite.TFLiteConverter.from_keras_model(model)
# tflite_model = converter.convert()

# with open('model.tflite', 'wb') as f:
#     f.write(tflite_model)

#################################################################

# print("Done Training")


def ourText(text):
  newTokens = nltk.word_tokenize(text)
  newTokens = [lm.lemmatize(word) for word in newTokens]
  return newTokens

def wordBag(text, vocab):
  newTokens = ourText(text)
  bagOfWords = [0]*len(vocab)
  for w in newTokens:
    for i,word in enumerate(vocab):
      if word ==w:
        bagOfWords[i]=1
  return np.array(bagOfWords)

def PClass(text,vocab,labels):
  bagOfWords = wordBag(text,vocab)
  ourResult = model.predict(np.array([bagOfWords]))[0]
  newThresh=0.2
  yp = [[i,res]for i,res in enumerate(ourResult) if res>newThresh]
  yp.sort(key=lambda x:x[1],reverse=True)
  newList=[]
  for r in yp:
    newList.append(labels[r[0]])
  return newList  


def getRes(firstList,fJson):
  tag = firstList[0]
  listOfIntents = fJson['intents']
  for i in listOfIntents:
    if i['tag']==tag:
      ourResult= random.choice(i['responses'])
      break
  return ourResult


# startPickling()


while True:
  newMessage = input(f"{Fore.BLUE}You : ")
  intents = PClass(newMessage,newWords,ourClasses)
  ourResult = getRes(intents,data)
  print(f"{Fore.GREEN}Chatbot : ",ourResult)